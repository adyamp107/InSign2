![Picture2](https://github.com/adyamp107/InSign2/assets/137896283/8f8212e8-8ddf-4f39-9e85-b5ac068b3c75)

# InSign2

InSign2 is an updated application from InSign1 (https://github.com/adyamp107/InSign1) and has the same function, namely being able to help deaf and mute people with disabilities to communicate with other people. Additionally, InSign2 provides a dataset collection tool that allows users to create multiple languages ​​without limitations. InSign2 also provides graph and table features so you can analyze the machine learning and deep learning training models that have been created. InSign2 provides various algorithms such as Random Forest, Decision Tree, K-Nearest Neighbors, Support Vector Machine, Naive Bayes, and Convolutional Neural Network.

## Some updates from InSign1:
1. More attractive UI.
2. Collection of more varied datasets, namely landmarks (.csv) and images (.jpg).
3. Six types of algorithms for training datasets, namely RandomForest, Decision Tree, K-Nearest neighbors, Naive Bayes, Support Vector Machine, and Convolutional Neural Network.
4. Display graphs and tables for each training file which makes it easier for users to analyze their training model.

## Additional information:

### Landmark type dataset (.csv):
1. Random Forest
2. Decision Trees
3. K-Nearest Neighbors
4. Naive Bayes
5. Support Vector Machine

Available graphs and tables:
1. Classification Report
2. Confusion Matrix
3. Error Rate

### Image type dataset (.jpg):
1. Convolutional Neural Networks

Available graphs and tables:
1. Classification Report
2. Confusion Matrix
3. Epoch Loss
4. Epoch Accuracy

## How to run the program

We recommend using python 3.8.10 and pip 24.0 to be able to download all the appropriate dependencies.

1. python --version (output: python 3.8.10)
2. pip --version (output: pip 24.0)

Example usage:

1. python -m venv venv
2. venv\Scripts\activate
3. pip install -r requirements.txt
4. python InSign.py

Just ignore any warnings that appear, and it should run fine.

## UI Display

Home Page:

![home](https://github.com/adyamp107/InSign2/assets/137896283/b93ce28e-bb0e-40a6-88a4-a0e9d1c11043)

Translate Page:

![translate](https://github.com/adyamp107/InSign2/assets/137896283/da343dd2-8796-48c8-8de3-a658e438b969)

Dataset Page (Add):

![dataset_add](https://github.com/adyamp107/InSign2/assets/137896283/ace76cd7-6ade-4044-be28-94aa58aa5b01)

Dataset Page (Delete):

![dataset_delete](https://github.com/adyamp107/InSign2/assets/137896283/3700cdf2-b759-4b9e-958a-de09afa7c831)

Dataset Page (Redata):

![dataset_redata](https://github.com/adyamp107/InSign2/assets/137896283/5d843912-dc07-4f7c-a5df-417db8ffa81c)

Dataset Page (Relabel):

![dataset_relabel](https://github.com/adyamp107/InSign2/assets/137896283/c523cfb2-3dc6-4163-be58-4a7b6db97470)

Training Page (Classification Report Random Forest):

![training_classification_report](https://github.com/adyamp107/InSign2/assets/137896283/ffd973ea-b68d-4fe5-9ddb-779c85bc3e2c)

Training Page (Confusion Matrix Random Forest):

![training_confusion_matrix](https://github.com/adyamp107/InSign2/assets/137896283/23178a23-fafa-4ab2-a587-ef457795a64b)

Training Page (Error Rate Random Forest):

![training_error_rate](https://github.com/adyamp107/InSign2/assets/137896283/432d58e5-eaa0-4ef3-b87b-f47023da5bdd)

Training Page (Epoch Loss Convolutional Neural Network):

![training_epoch_loss](https://github.com/adyamp107/InSign2/assets/137896283/84eac74f-b07e-4232-8ab3-31258865a984)

Training Page (Epoch Accuracy Convolutional Neural Network):

![training_epoch_accuracy](https://github.com/adyamp107/InSign2/assets/137896283/304171f8-fb88-42f8-9b67-24c4401a2644)

History Page:

![history](https://github.com/adyamp107/InSign2/assets/137896283/2667d744-f25b-4679-86f2-35f884d00027)

Setting Page:

![setting](https://github.com/adyamp107/InSign2/assets/137896283/fbe9a9b1-6d8c-4ba8-a3ba-f3ec972cfccb)
